{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Found 104 images belonging to 4 classes.\n",
      "Found 104 images belonging to 4 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,477,188\n",
      "Trainable params: 4,473,220\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7807 - accuracy: 0.3500 - val_loss: 1.2966 - val_accuracy: 0.4062\n",
      "\n",
      "Epoch 00001: saving model to model_weights.h5\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.3254 - accuracy: 0.3250 - val_loss: 1.6673 - val_accuracy: 0.4531\n",
      "\n",
      "Epoch 00002: saving model to model_weights.h5\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.2946 - accuracy: 0.4500 - val_loss: 2.0955 - val_accuracy: 0.3125\n",
      "\n",
      "Epoch 00003: saving model to model_weights.h5\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.1448 - accuracy: 0.5250 - val_loss: 2.1080 - val_accuracy: 0.2812\n",
      "\n",
      "Epoch 00004: saving model to model_weights.h5\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.2278 - accuracy: 0.3750 - val_loss: 2.1945 - val_accuracy: 0.1406\n",
      "\n",
      "Epoch 00005: saving model to model_weights.h5\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9109 - accuracy: 0.5250 - val_loss: 1.9937 - val_accuracy: 0.2656\n",
      "\n",
      "Epoch 00006: saving model to model_weights.h5\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.0733 - accuracy: 0.5500 - val_loss: 1.9739 - val_accuracy: 0.1406\n",
      "\n",
      "Epoch 00007: saving model to model_weights.h5\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2468 - accuracy: 0.5469 - val_loss: 1.8983 - val_accuracy: 0.2031\n",
      "\n",
      "Epoch 00008: saving model to model_weights.h5\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9490 - accuracy: 0.6000 - val_loss: 1.8206 - val_accuracy: 0.2656\n",
      "\n",
      "Epoch 00009: saving model to model_weights.h5\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1971 - accuracy: 0.4750 - val_loss: 1.8484 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00010: saving model to model_weights.h5\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.1406 - accuracy: 0.5156 - val_loss: 1.7632 - val_accuracy: 0.2031\n",
      "\n",
      "Epoch 00011: saving model to model_weights.h5\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9500 - accuracy: 0.5750 - val_loss: 1.7829 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00012: saving model to model_weights.h5\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.2632 - accuracy: 0.4375 - val_loss: 1.7491 - val_accuracy: 0.1406\n",
      "\n",
      "Epoch 00013: saving model to model_weights.h5\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1291 - accuracy: 0.5250 - val_loss: 1.5982 - val_accuracy: 0.2656\n",
      "\n",
      "Epoch 00014: saving model to model_weights.h5\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.2833 - accuracy: 0.5000 - val_loss: 1.6634 - val_accuracy: 0.1875\n",
      "\n",
      "Epoch 00015: saving model to model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To set the backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "def startmodeltraining()\n",
    "    img_size = 48\n",
    "    batch_size = 64\n",
    "\n",
    "    datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
    "    train_generator = datagen_train.flow_from_directory(\"facedata/\",\n",
    "                                                    target_size=(img_size,img_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    datagen_validation = ImageDataGenerator(horizontal_flip=True)\n",
    "    validation_generator = datagen_validation.flow_from_directory(\"facedata/\",\n",
    "                                                    target_size=(img_size,img_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "    model = Sequential()\n",
    "\n",
    "# 1st Convolution Layer\n",
    "\n",
    "# There are 64 (3,3) filters with \"same\" Padding and Shape of the Input_Image is (48,48,1)\n",
    "    model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "    model.add(Activation('relu'))  \n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2nd Convolution layer\n",
    "\n",
    "# There are 128 (5,5) filters with \"same\" Padding \n",
    "    model.add(Conv2D(128,(5,5), padding='same'))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3rd Convolution layer\n",
    "\n",
    "# There are 512 (3,3) filters with \"same\" Padding \n",
    "\n",
    "    model.add(Conv2D(512,(3,3), padding='same'))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4th Convolution layer\n",
    "\n",
    "# There are 512 (3,3) filters with \"same\" Padding \n",
    "    model.add(Conv2D(512,(3,3), padding='same'))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop \n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "# Flattening\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "# Fully connected layer with 256 nuerons\n",
    "    model.add(Dense(256))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "# Fully connected layer with 512 nuerons\n",
    "    model.add(Dense(512))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "# Adding a final Dense Layer with 7 outputs corresponding to 7 different emotions with a \"softmax\" Activation Function \n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent \n",
    "# procedure to update network weights iterative based in training data.\n",
    "\n",
    "# Let us choose a Learning rate of 0.0005 \n",
    "    opt = Adam(lr=0.0005)\n",
    "\n",
    "\n",
    "# Compile defines the loss function, the optimizer and the metrics.\n",
    "\n",
    "# As we have Categorical Values we will use 'categorical_crossentropy' loss function\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Let us check the details of the Model\n",
    "    model.summary()\n",
    "# Let us train the Model 15 times\n",
    "    epochs = 15\n",
    "\n",
    "    steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "    validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "    \n",
    "# Create a Callback which reduces the Learning rate by a factor of \"0.1\" when the val_loss does not decrease\n",
    "# after 2 epochs also and allowing the minimum value of Learning Rate to be 0.00001\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=2, min_lr=0.00001, mode='auto')\n",
    "\n",
    "\n",
    "# Create another Callback which saves the Model Weights by monitoring the Val_Accuracy\n",
    "    checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n",
    "                             save_weights_only=True, mode='max', verbose=1)\n",
    "\n",
    "\n",
    "# A callback is an object that can perform actions at various stages of training\n",
    "# (e.g. at the start or end of an epoch, before or after a single batch, etc).\n",
    "    callbacks = [checkpoint, reduce_lr]\n",
    "\n",
    "# Fitting the model .\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_steps,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "# Converting the model into JSON format and storing it in \"fer_model.json\" file. \n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
